{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step-1 : WebScraping**\n",
        "\n"
      ],
      "metadata": {
        "id": "5OsBhaFZ26Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "def scrape_nifty_50_combined():\n",
        "    url = 'https://www.moneycontrol.com/stocks/marketstats/indexcomp.php?optex=NSE&opttopic=indexcomp&index=9'\n",
        "\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    driver.get(url)\n",
        "    time.sleep(5)\n",
        "\n",
        "    # First, try to find table directly\n",
        "    try:\n",
        "        WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.CLASS_NAME, 'tbldata14'))\n",
        "        )\n",
        "    except:\n",
        "        pass  # We'll check iframe fallback next\n",
        "\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    table = soup.find('table', {'class': 'tbldata14'})\n",
        "\n",
        "    # Try iframes if not found\n",
        "    if table is None:\n",
        "        iframes = driver.find_elements(By.TAG_NAME, 'iframe')\n",
        "        print(f\"[Info] Table not found in main page. Found {len(iframes)} iframe(s). Trying each iframe...\")\n",
        "        for i, iframe in enumerate(iframes):\n",
        "            try:\n",
        "                driver.switch_to.frame(iframe)\n",
        "                iframe_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "                table = iframe_soup.find('table', {'class': 'tbldata14'})\n",
        "                if table:\n",
        "                    soup = iframe_soup\n",
        "                    print(f\"[Success] Found table in iframe index {i}.\")\n",
        "                    break\n",
        "                driver.switch_to.default_content()\n",
        "            except Exception as e:\n",
        "                print(f\"[Warning] Could not switch to iframe {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Close driver\n",
        "    driver.quit()\n",
        "\n",
        "    # Final fallback: try pandas.read_html\n",
        "    if table is None:\n",
        "        print(\"[Fallback] Trying pandas.read_html...\")\n",
        "        try:\n",
        "            dfs = pd.read_html(url)\n",
        "            for df in dfs:\n",
        "                if 'Stock Name' in df.columns or df.shape[1] >= 6:\n",
        "                    df['Scraped On'] = datetime.now().strftime('%Y-%m-%d')\n",
        "                    return df\n",
        "            raise ValueError(\"Fallback succeeded but didn't find expected data structure.\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"All methods failed. {e}\")\n",
        "\n",
        "    # Parse the table using BeautifulSoup\n",
        "    rows = table.find_all('tr')[1:]\n",
        "    data = []\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        if len(cols) >= 6:\n",
        "            try:\n",
        "                data.append({\n",
        "                    'Stock Name': cols[0].text.strip(),\n",
        "                    'Last Price': float(cols[1].text.strip().replace(',', '')),\n",
        "                    'Change': float(cols[2].text.strip().replace(',', '').replace('+', '')),\n",
        "                    'Change(%)': float(cols[3].text.strip().replace('%', '').replace('+', '')),\n",
        "                    'Volume': int(cols[4].text.strip().replace(',', '')),\n",
        "                    'Value(Rs Lakhs)': float(cols[5].text.strip().replace(',', '')),\n",
        "                    'Scraped On': datetime.now().strftime('%Y-%m-%d')\n",
        "                })\n",
        "            except ValueError:\n",
        "                continue  # Skip bad rows\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Run and print\n",
        "if __name__ == '__main__':\n",
        "    df_nifty = scrape_nifty_50_combined()\n",
        "    print(df_nifty.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y_EgNYLq2vw4",
        "outputId": "d5fde56a-4e00-48a8-a2a0-aa9a3872d980"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Table not found in main page. Found 0 iframe(s). Trying each iframe...\n",
            "[Fallback] Trying pandas.read_html...\n",
            "                                 Company Name                        Industry  \\\n",
            "0  Adani EnterprisAdd toWatchlist | Portfolio                         Trading   \n",
            "1      Adani PortsAdd toWatchlist | Portfolio        Transport Infrastructure   \n",
            "2  Apollo HospitalAdd toWatchlist | Portfolio  Hospital & Healthcare Services   \n",
            "3     Asian PaintsAdd toWatchlist | Portfolio                          Paints   \n",
            "4        Axis BankAdd toWatchlist | Portfolio                  Bank - Private   \n",
            "\n",
            "   Last Price     Chg  %Chg  Mkt Cap (Rs cr)  Scraped On  \n",
            "0     2511.00   49.85  2.03        289814.78  2025-05-15  \n",
            "1     1404.70   33.70  2.46        303434.72  2025-05-15  \n",
            "2     7025.00  108.00  1.56        101008.72  2025-05-15  \n",
            "3     2326.00   42.35  1.85        223109.41  2025-05-15  \n",
            "4     1216.15   20.60  1.72        376805.02  2025-05-15  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step-2 : Feature_Engineering**"
      ],
      "metadata": {
        "id": "AQv5ujBu3FPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(df):\n",
        "    df['Price Category'] = pd.cut(df['Last Price'],\n",
        "                                  bins=[0, 500, 1000, 2000, df['Last Price'].max()],\n",
        "                                  labels=['Low', 'Mid', 'High', 'Very High'])\n",
        "\n",
        "    df['Gain/Loss'] = df['Chg'].apply(lambda x: 'Gain' if x > 0 else ('Loss' if x < 0 else 'No Change'))\n",
        "\n",
        "    df['Trend Signal'] = df['%Chg'].apply(lambda x:\n",
        "                                                'Strong Gain' if x >= 2 else\n",
        "                                                'Mild Gain' if 0 < x < 2 else\n",
        "                                                'Flat' if x == 0 else\n",
        "                                                'Mild Loss' if -2 < x < 0 else\n",
        "                                                'Strong Loss')\n",
        "\n",
        "    df['Day of Week'] = pd.to_datetime(df['Scraped On']).dt.day_name()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Wa8Q3J6X25T5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saving_file():\n",
        "    df = scrape_nifty_50_combined()\n",
        "    df = feature_engineering(df)\n",
        "\n",
        "    # Save history\n",
        "    try:\n",
        "        old_df = pd.read_csv('nifty_50_data_history.csv')\n",
        "        df = pd.concat([old_df, df], ignore_index=True)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "    df.to_csv('nifty_50_data_history.csv', index=False)\n",
        "    print(\"✅ Enhanced data saved with feature engineering.\")\n",
        "\n",
        "# 4. Execute\n",
        "if __name__ == '__main__':\n",
        "    saving_file()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tpjVK1aw4j_Q",
        "outputId": "b0433a7f-4233-4ea4-fc41-a9a05d4d0f64"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Table not found in main page. Found 0 iframe(s). Trying each iframe...\n",
            "[Fallback] Trying pandas.read_html...\n",
            "✅ Enhanced data saved with feature engineering.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('nifty_50_data_history.csv')\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OOvm2t80G8eF",
        "outputId": "34486d0d-5dc4-4d1a-c5ca-0962016a9186"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Company Name                        Industry  \\\n",
            "0  Adani EnterprisAdd toWatchlist | Portfolio                         Trading   \n",
            "1      Adani PortsAdd toWatchlist | Portfolio        Transport Infrastructure   \n",
            "2  Apollo HospitalAdd toWatchlist | Portfolio  Hospital & Healthcare Services   \n",
            "3     Asian PaintsAdd toWatchlist | Portfolio                          Paints   \n",
            "4        Axis BankAdd toWatchlist | Portfolio                  Bank - Private   \n",
            "\n",
            "   Last Price    Chg  %Chg  Mkt Cap (Rs cr)  Scraped On Price Category  \\\n",
            "0      2507.1  45.95  1.87        289364.65  2025-05-15      Very High   \n",
            "1      1402.0  31.00  2.26        302851.48  2025-05-15           High   \n",
            "2      7000.0  83.00  1.20        100649.26  2025-05-15      Very High   \n",
            "3      2319.3  35.65  1.56        222466.74  2025-05-15      Very High   \n",
            "4      1209.3  13.75  1.15        374682.66  2025-05-15           High   \n",
            "\n",
            "  Gain/Loss Trend Signal Day of Week  \n",
            "0      Gain    Mild Gain    Thursday  \n",
            "1      Gain  Strong Gain    Thursday  \n",
            "2      Gain    Mild Gain    Thursday  \n",
            "3      Gain    Mild Gain    Thursday  \n",
            "4      Gain    Mild Gain    Thursday  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "80VtgiRBHfoM",
        "outputId": "cbe88fae-0af7-4b76-ea61-6788ca01188a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "af0NrF-zHldc",
        "outputId": "81ef6d16-0d04-4bef-9170-e56b693ac808"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'nifty_50_data_history.csv', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('nifty_50_data_history.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8DFzZ8_kHyUE",
        "outputId": "312557fe-4086-4011-f423-f457a62d92ce"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dbaea1a2-7ec8-4642-8888-7a0a94c3c7ec\", \"nifty_50_data_history.csv\", 6492)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qAtN_q3lFuYs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GivXxFEWMVQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}